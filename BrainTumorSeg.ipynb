{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BrainTumorSeg.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shivg7706/BrainTumorSegmentation/blob/master/BrainTumorSeg.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rPf1OMLfU99R",
        "colab_type": "code",
        "outputId": "91c5f082-6153-4413-aae1-27fd6f0bad1f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qpg2SrOUbUlg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp ./drive/My\\ Drive/seg_data.zip ./"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K3hx8H6TzgCF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip seg_data.zip\n",
        "!rm -rf seg_data.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mpRyoPYfSZGI",
        "colab_type": "text"
      },
      "source": [
        "## Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dThkkln_bcSk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import requests\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "import os\n",
        "import argparse\n",
        "\n",
        "\n",
        "\n",
        "def download_file(url, path):\n",
        "\n",
        "    if check_if_file_exits(path):\n",
        "        print(f'Already existing file {path}')\n",
        "        return\n",
        "\n",
        "    # Deleting the partial downloaded file.\n",
        "    if os.path.isfile(path):\n",
        "        print(f'Deleted existing partial file {path}')\n",
        "        os.remove(path)\n",
        "\n",
        "    response = requests.get(url, stream=True)\n",
        "    handle = open(path, \"wb\")\n",
        "    with open(path, \"wb\") as handle:\n",
        "        chunk_size = 1024\n",
        "        total_size = round(int(response.headers['Content-Length']), 3)\n",
        "        pbar = tqdm(unit=\"B\", total=total_size)\n",
        "        for chunk in response.iter_content(chunk_size=chunk_size):\n",
        "            if chunk:  # filter out keep-alive new chunks\n",
        "                handle.write(chunk)\n",
        "                pbar.update(len(chunk))\n",
        "\n",
        "\n",
        "    extension = path[-3:]\n",
        "    os.rename(path, path[:-4]+'_done.'+extension)\n",
        "\n",
        "\n",
        "def make_folder(target_folder):\n",
        "\n",
        "    if not (os.path.isdir(target_folder)):\n",
        "        print(f'Creating {target_folder} folder')\n",
        "        os.mkdir(target_folder)\n",
        "\n",
        "\n",
        "def main():\n",
        "\n",
        "    dataset_urls = ['https://ndownloader.figshare.com/files/3381290',\n",
        "                    'https://ndownloader.figshare.com/files/3381296',\n",
        "                    'https://ndownloader.figshare.com/files/3381293',\n",
        "                    'https://ndownloader.figshare.com/files/3381302']\n",
        "\n",
        "    dataset_readme = 'https://ndownloader.figshare.com/files/7953679'\n",
        "\n",
        "    target_folder = 'dataset'\n",
        "    dataset_part = 1\n",
        "    dataset_file_name = f'brain_tumor_dataset_part_'\n",
        "\n",
        "    make_folder(target_folder)\n",
        "\n",
        "    print('Downloading dataset README.txt\\n')\n",
        "    download_file(dataset_readme, os.path.join(target_folder, 'README.TXT'))\n",
        "\n",
        "    print('Starting download process\\n')\n",
        "    for url in dataset_urls:\n",
        "        try:\n",
        "            path = os.path.join(\n",
        "                target_folder, f'{dataset_file_name}{dataset_part}.zip')\n",
        "            print(f'\\t\\tDownloading :  {path}')\n",
        "            download_file(url, path)\n",
        "            dataset_part += 1\n",
        "\n",
        "\n",
        "\n",
        "main()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "onDxLi66LO43",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tdAI4-_jVELG",
        "colab_type": "text"
      },
      "source": [
        "## Converting Data from `.mat` files into images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rIsmpTfNOeDP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import h5py\n",
        "import numpy as np\n",
        "import tensorflow as tftype('float32')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5c0-ry_YQbSO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mapping = {\n",
        "    1: 'meningioma',\n",
        "    2: 'glioma',\n",
        "    3: 'pituitary'\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g-PSb73Zajxi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_it(data):\n",
        "    \n",
        "    mpimg.imsave('./tumorImage/{}_tumor_{}.png'.format(data['count'], data['label']), data['image'], cmap='gray', format='png')\n",
        "    mpimg.imsave('./maskImage/{}_mask_{}.png'.format(data['count'], data['label']), data['mask'], cmap='gray', format='png')\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G5iyG4psRCu7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.image as mpimg\n",
        "\n",
        "for file in tqdm(os.listdir('./dataset')):\n",
        "    f = h5py.File('./dataset/{}'.format(file))\n",
        "    data = dict()\n",
        "    data['count'] = file[:-4]\n",
        "    data['image'] = np.array(f.get('cjdata/image'))\n",
        "    data['mask'] = np.array(f.get('cjdata/tumorMask'))\n",
        "    data['label'] = mapping[np.array(f.get('cjdata/label'))[0, 0]]\n",
        "\n",
        "    save_it(data)\n",
        "        \n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6cSnnTHjYCG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "for i in range(3001, 3065):\n",
        "    os.rename('./tumor/{}.png'.format(i), '../test_tumor/{}.png'.format(i))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3IgB8O2pWRlv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mv ../test/ ../test_mask"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Bsi0aMqkaL6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for file in os.listdir('segmentation_dataset/maskImage/'):\n",
        "    if not os.path.exists('segmentation_dataset/maskImage/mask'):\n",
        "        os.mkdir('segmentation_dataset/maskImage/mask')\n",
        "    os.rename('segmentation_dataset/maskImage/{}'.format(file), 'segmentation_dataset/maskImage/mask/{}'.format(file))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "t7GqhvmyJyUy",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "seed = 1\n",
        "np.random.seed(seed)\n",
        "\n",
        "def my_generator(batch_size=4):\n",
        "    \n",
        "#     while True:\n",
        "        tumors = []\n",
        "        masks = []\n",
        "        choose = np.random.randint(1, 3000, size=batch_size)\n",
        "#         print(choose)\n",
        "        for i in choose:\n",
        "            \n",
        "            tumor = cv2.imread('segmentation_dataset/tumorImage/tumor/{}.png'.format(i), 0) / 255\n",
        "#             tumor = cv2.resize(tumor, (256, 256)) / 255\n",
        "            plt.imshow(tumor, cmap='gray')\n",
        "            plt.draw()\n",
        "            plt.pause(0.2)\n",
        "            tumor = tumor[:, :, np.newaxis]\n",
        "            tumors.append(tumor)\n",
        "            \n",
        "            mask = cv2.imread('segmentation_dataset/maskImage/mask/{}.png'.format(i), 0) / 255\n",
        "#             mask = cv2.resize(tumor, (256, 256)) / 255\n",
        "            plt.imshow(mask, cmap='gray')\n",
        "            plt.draw()\n",
        "            plt.pause(0.2)\n",
        "            mask = mask[:, :, np.newaxis]\n",
        "            masks.append(mask)\n",
        "            \n",
        "        \n",
        "        tumors = np.asarray(tumors)\n",
        "#         print(tumors.shape)\n",
        "        masks = np.asarray(masks)\n",
        "#         if tumors.ndim == 4:\n",
        "#             yield (tumors, masks)\n",
        "#             \n",
        "            "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R4VPLXHuC7vG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import cv2\n",
        "\n",
        "for img in os.listdir('./segmentation_dataset/maskImage/mask/'):\n",
        "    \n",
        "    imag = cv2.imread('./segmentation_dataset/maskImage/mask/'  + img, 0)\n",
        "    print(imag.shape)\n",
        "    os.system('clear')\n",
        "    if imag.shape == (256, 256):\n",
        "        os.remove('./segmentation_dataset/maskImage/mask/{}'.format(img))\n",
        "        os.remove('./segmentation_dataset/tumorImage/tumor/{}'.format(img))\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7fQ7ttZIJzpu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img1 = cv2.imread('segmentation_dataset/tumorImage/tumor/300.png', 0)/255\n",
        "img1 = img1[:, :, np.newaxis]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6DT-Rc0H2YwL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def combine(img_gen, mask_gen):\n",
        "    while True:\n",
        "        yield(img_gen.next(), mask_gen.next())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ggUjx8TMo9dA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "import os\n",
        "import random\n",
        "\n",
        "def data_gen(img_folder, mask_folder, batch_size):\n",
        "    c = 0\n",
        "    n = os.listdir(img_folder) #List of training images\n",
        "    print(n)\n",
        "    random.shuffle(n)\n",
        "  \n",
        "    while (True):\n",
        "        img = np.zeros((batch_size, 512, 512, 3)).astype('float')\n",
        "        mask = np.zeros((batch_size, 512, 512, 1)).astype('float')\n",
        "\n",
        "        for i in range(c, c+batch_size): #initially from 0 to 16, c = 0. \n",
        "\n",
        "            train_img = cv2.imread(img_folder+'/'+n[i])/255.\n",
        "            train_img =  cv2.resize(train_img, (512, 512))# Read an image from folder and resize\n",
        "\n",
        "            img[i-c] = train_img #add to array - img[0], img[1], and so on.\n",
        "\n",
        "\n",
        "            train_mask = cv2.imread(mask_folder+'/'+n[i], cv2.IMREAD_GRAYSCALE)/255.\n",
        "            train_mask = cv2.resize(train_mask, (512, 512))\n",
        "            train_mask = train_mask.reshape(512, 512, 1) # Add extra dimension for parity with train_img size [512 * 512 * 3]\n",
        "\n",
        "            mask[i-c] = train_mask\n",
        "\n",
        "        c+=batch_size\n",
        "        if(c+batch_size>=len(os.listdir(img_folder))):\n",
        "            c=0\n",
        "            random.shuffle(n)\n",
        "                  # print \"randomizing again\"\n",
        "        yield img, mask\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "train_frame_path = './segmentation_dataset/tumorImage/tumor/'\n",
        "train_mask_path = './segmentation_dataset/maskImage/mask/'\n",
        "\n",
        "# val_frame_path = '/path/to/validation_frames'\n",
        "# val_mask_path = '/path/to/validation_frames'\n",
        "\n",
        "# Train the model\n",
        "train_gen = data_gen(train_frame_path,train_mask_path, batch_size = 4)\n",
        "# val_gen = data_gen(val_frame_path,val_mask_path, batch_size = 4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K_7hoLpsdKEw",
        "colab_type": "text"
      },
      "source": [
        "## Training part"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BctKQ_pE7_U_",
        "colab_type": "code",
        "outputId": "62b7dcd3-cf69-45cf-c54e-3bba977b8062",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "data_gen_args = dict(rescale=1./255)\n",
        "\n",
        "image_datagen = ImageDataGenerator(**data_gen_args)\n",
        "mask_datagen = ImageDataGenerator(**data_gen_args)\n",
        "\n",
        "seed = 1\n",
        "\n",
        "img_gen = image_datagen.flow_from_directory('segmentation_dataset/tumorImage/', batch_size=1, target_size=(512, 512),\n",
        "                                       class_mode=None, seed=seed, color_mode='grayscale', shuffle=True)\n",
        "mask_gen = mask_datagen.flow_from_directory('segmentation_dataset/maskImage/', batch_size=1, target_size=(512, 512),\n",
        "                                       class_mode=None, seed=seed, color_mode='grayscale', shuffle=True)\n",
        "\n",
        "train_gen = combine(img_gen, mask_gen)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 3064 images belonging to 1 classes.\n",
            "Found 3064 images belonging to 1 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1We8RlQHZBVr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.python.keras.layers.convolutional import Conv2D, ZeroPadding2D, Conv2DTranspose\n",
        "from tensorflow.python.keras.layers.pooling import MaxPool2D, AvgPool2D, GlobalAveragePooling2D\n",
        "from tensorflow.python.keras.layers import Dense, Flatten, Input, BatchNormalization, Dropout, Activation, Concatenate, concatenate, Add, UpSampling2D\n",
        "from tensorflow.python.keras.models import Model, Sequential\n",
        "from tensorflow.python.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
        "import tensorflow.keras.backend as K\n",
        "from tensorflow.python.keras.optimizers import Adam\n",
        "from tensorflow.python.keras.utils import plot_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJ6oM6IUplOU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "60ff8698-2aa0-4c88-e94d-b9d067f446de"
      },
      "source": [
        "from keras.layers import LeakyReLU\n",
        "from tensorflow.python.keras.optimizers import Adam\n",
        "\n",
        "def get_conv_block(input, filter):\n",
        "    \n",
        "    x = input\n",
        "    \n",
        "    for i in range(2):\n",
        "        x = Conv2D(filter, 3, padding='same', activation='relu', kernel_initializer='he_normal')(x)\n",
        "        x = BatchNormalization()(x)\n",
        "        \n",
        "    return x"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZNDVnSfmLi6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def unet():\n",
        "    \n",
        "    f = [16, 32, 64, 128, 256]\n",
        "    \n",
        "    inputs = Input((512, 512, 1), name='input')\n",
        "    \n",
        "    # Encoder\n",
        "    block1 = get_conv_block(inputs, f[0])\n",
        "    x = MaxPool2D(2)(block1)\n",
        "    \n",
        "    block2 = get_conv_block(x, f[1])\n",
        "    x = MaxPool2D(2)(block2)\n",
        "    \n",
        "    block3 = get_conv_block(x, f[2])\n",
        "    x = MaxPool2D(2)(block3)\n",
        "    \n",
        "    block4 = get_conv_block(x, f[3])\n",
        "    \n",
        "    # Middle part\n",
        "    \n",
        "    x = MaxPool2D(2)(block4)\n",
        "    x = get_conv_block(x, f[4])\n",
        "    \n",
        "    # Decoder\n",
        "    \n",
        "    x = Conv2DTranspose(f[3], kernel_size=2, strides=2)(x)\n",
        "    x = Concatenate()([block4, x])\n",
        "    x = get_conv_block(x, f[3])\n",
        "    \n",
        "    x = Conv2DTranspose(f[2], kernel_size=2, strides=2)(x)\n",
        "    x = Concatenate()([block3, x])\n",
        "    x = get_conv_block(x, f[2])\n",
        "    \n",
        "    x = Conv2DTranspose(f[1], kernel_size=2, strides=2)(x)\n",
        "    x = Concatenate()([block2, x])\n",
        "    x = get_conv_block(x, f[1])\n",
        "    \n",
        "    x = Conv2DTranspose(f[0], kernel_size=2, strides=2)(x)\n",
        "    x = Concatenate()([block1, x])\n",
        "    x = get_conv_block(x, f[0])\n",
        "    \n",
        "    outputs = Conv2D(1, 1, activation='sigmoid', padding='same')(x)\n",
        "    opt = Adam(lr=1e-4)\n",
        "    model = Model(inputs, outputs)\n",
        "    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=[dice_coef])\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PRW8xRmwnb5y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def iou_loss_core(y_true, y_pred, smooth=0.005):\n",
        "    intersection = K.sum(K.abs(y_true * y_pred), axis=-1)\n",
        "    union = K.sum(y_true,-1) + K.sum(y_pred,-1) - intersection\n",
        "    iou = (intersection + smooth) / ( union + smooth)\n",
        "    return iou"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8TFQCyvI8NhE",
        "colab": {}
      },
      "source": [
        "def dice_coef(y_true, y_pred):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    coef = (2. * intersection + 1) / (K.sum(y_true_f) + K.sum(y_pred_f) + 1)\n",
        "    \n",
        "    return coef\n",
        "\n",
        "def dice_coef_loss(y_true, y_pred):\n",
        "    return 1-dice_coef(y_true, y_pred)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S4DTr1vr8Ok4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.python.ops import clip_ops\n",
        "def _constant_to_tensor(x, dtype):\n",
        "\n",
        "    return constant_op.constant(x, dtype=dtype)\n",
        "\n",
        "\n",
        "def loss_tensor(y_true, y_pred):\n",
        "    \n",
        "    epsilon_ = _constant_to_tensor(K.epsilon(), y_pred.dtype.base_dtype)\n",
        "    y_pred = clip_ops.clip_by_value(y_pred, epsilon_, 1.0-epsilon_)\n",
        "    out = -(y_true * K.log(y_pred) + (1.0 - y_true) * K.log(1.0 - y_pred))\n",
        "    return K.mean(out, axis=-1)\n",
        "     "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hpiw6D_9twa-",
        "colab_type": "code",
        "outputId": "0b9af4bc-5eda-40a6-e389-f0a2e435e31a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model = ResUNet()\n",
        "model.compile(optimizer='adam', loss=dice_coef_loss, metrics=[dice_coef])\n",
        "model.summary()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_3 (InputLayer)            [(None, 512, 512, 1) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 512, 512, 16) 160         input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 512, 512, 16) 64          conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 512, 512, 16) 0           batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 512, 512, 16) 32          input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 512, 512, 16) 2320        activation_38[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, 512, 512, 16) 64          conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_18 (Add)                    (None, 512, 512, 16) 0           conv2d_61[0][0]                  \n",
            "                                                                 batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, 512, 512, 16) 64          add_18[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 512, 512, 16) 0           batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 256, 256, 32) 4640        activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, 256, 256, 32) 128         conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 256, 256, 32) 544         add_18[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 256, 256, 32) 0           batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, 256, 256, 32) 128         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 256, 256, 32) 9248        activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_19 (Add)                    (None, 256, 256, 32) 0           batch_normalization_60[0][0]     \n",
            "                                                                 conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, 256, 256, 32) 128         add_19[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 256, 256, 32) 0           batch_normalization_61[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 128, 128, 64) 18496       activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, 128, 128, 64) 256         conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 128, 128, 64) 2112        add_19[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 128, 128, 64) 0           batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, 128, 128, 64) 256         conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 128, 128, 64) 36928       activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_20 (Add)                    (None, 128, 128, 64) 0           batch_normalization_63[0][0]     \n",
            "                                                                 conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, 128, 128, 64) 256         add_20[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 128, 128, 64) 0           batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 64, 64, 128)  73856       activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, 64, 64, 128)  512         conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_71 (Conv2D)              (None, 64, 64, 128)  8320        add_20[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 64, 64, 128)  0           batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, 64, 64, 128)  512         conv2d_71[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_70 (Conv2D)              (None, 64, 64, 128)  147584      activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_21 (Add)                    (None, 64, 64, 128)  0           batch_normalization_66[0][0]     \n",
            "                                                                 conv2d_70[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, 64, 64, 128)  512         add_21[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 64, 64, 128)  0           batch_normalization_67[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_72 (Conv2D)              (None, 32, 32, 256)  295168      activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, 32, 32, 256)  1024        conv2d_72[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_74 (Conv2D)              (None, 32, 32, 256)  33024       add_21[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 32, 32, 256)  0           batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, 32, 32, 256)  1024        conv2d_74[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_73 (Conv2D)              (None, 32, 32, 256)  590080      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_22 (Add)                    (None, 32, 32, 256)  0           batch_normalization_69[0][0]     \n",
            "                                                                 conv2d_73[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_70 (BatchNo (None, 32, 32, 256)  1024        add_22[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 32, 32, 256)  0           batch_normalization_70[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_75 (Conv2D)              (None, 32, 32, 256)  590080      activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_71 (BatchNo (None, 32, 32, 256)  1024        conv2d_75[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 32, 32, 256)  0           batch_normalization_71[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_76 (Conv2D)              (None, 32, 32, 256)  590080      activation_48[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_8 (UpSampling2D)  (None, 64, 64, 256)  0           conv2d_76[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_8 (Concatenate)     (None, 64, 64, 384)  0           up_sampling2d_8[0][0]            \n",
            "                                                                 add_21[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_72 (BatchNo (None, 64, 64, 384)  1536        concatenate_8[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 64, 64, 384)  0           batch_normalization_72[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_77 (Conv2D)              (None, 64, 64, 256)  884992      activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_73 (BatchNo (None, 64, 64, 256)  1024        conv2d_77[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_79 (Conv2D)              (None, 64, 64, 256)  98560       concatenate_8[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 64, 64, 256)  0           batch_normalization_73[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_74 (BatchNo (None, 64, 64, 256)  1024        conv2d_79[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_78 (Conv2D)              (None, 64, 64, 256)  590080      activation_50[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_23 (Add)                    (None, 64, 64, 256)  0           batch_normalization_74[0][0]     \n",
            "                                                                 conv2d_78[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_9 (UpSampling2D)  (None, 128, 128, 256 0           add_23[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_9 (Concatenate)     (None, 128, 128, 320 0           up_sampling2d_9[0][0]            \n",
            "                                                                 add_20[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_75 (BatchNo (None, 128, 128, 320 1280        concatenate_9[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 128, 128, 320 0           batch_normalization_75[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_80 (Conv2D)              (None, 128, 128, 128 368768      activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_76 (BatchNo (None, 128, 128, 128 512         conv2d_80[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_82 (Conv2D)              (None, 128, 128, 128 41088       concatenate_9[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 128, 128, 128 0           batch_normalization_76[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_77 (BatchNo (None, 128, 128, 128 512         conv2d_82[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_81 (Conv2D)              (None, 128, 128, 128 147584      activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_24 (Add)                    (None, 128, 128, 128 0           batch_normalization_77[0][0]     \n",
            "                                                                 conv2d_81[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_10 (UpSampling2D) (None, 256, 256, 128 0           add_24[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_10 (Concatenate)    (None, 256, 256, 160 0           up_sampling2d_10[0][0]           \n",
            "                                                                 add_19[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_78 (BatchNo (None, 256, 256, 160 640         concatenate_10[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 256, 256, 160 0           batch_normalization_78[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_83 (Conv2D)              (None, 256, 256, 64) 92224       activation_53[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_79 (BatchNo (None, 256, 256, 64) 256         conv2d_83[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_85 (Conv2D)              (None, 256, 256, 64) 10304       concatenate_10[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 256, 256, 64) 0           batch_normalization_79[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_80 (BatchNo (None, 256, 256, 64) 256         conv2d_85[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_84 (Conv2D)              (None, 256, 256, 64) 36928       activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_25 (Add)                    (None, 256, 256, 64) 0           batch_normalization_80[0][0]     \n",
            "                                                                 conv2d_84[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_11 (UpSampling2D) (None, 512, 512, 64) 0           add_25[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_11 (Concatenate)    (None, 512, 512, 80) 0           up_sampling2d_11[0][0]           \n",
            "                                                                 add_18[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_81 (BatchNo (None, 512, 512, 80) 320         concatenate_11[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 512, 512, 80) 0           batch_normalization_81[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_86 (Conv2D)              (None, 512, 512, 32) 23072       activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_82 (BatchNo (None, 512, 512, 32) 128         conv2d_86[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_88 (Conv2D)              (None, 512, 512, 32) 2592        concatenate_11[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 512, 512, 32) 0           batch_normalization_82[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_83 (BatchNo (None, 512, 512, 32) 128         conv2d_88[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_87 (Conv2D)              (None, 512, 512, 32) 9248        activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_26 (Add)                    (None, 512, 512, 32) 0           batch_normalization_83[0][0]     \n",
            "                                                                 conv2d_87[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_89 (Conv2D)              (None, 512, 512, 1)  33          add_26[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 4,722,737\n",
            "Trainable params: 4,715,441\n",
            "Non-trainable params: 7,296\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yoC7Xx7lc6Wq",
        "colab_type": "text"
      },
      "source": [
        "## ResUNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ux1Yit-9wHI4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def bn_act(x, act=True):\n",
        "    x = BatchNormalization()(x)\n",
        "    if act == True:\n",
        "        x = Activation(\"relu\")(x)\n",
        "    return x\n",
        "\n",
        "def conv_block(x, filters, kernel_size=(3, 3), padding=\"same\", strides=1):\n",
        "    conv = bn_act(x)\n",
        "    conv = Conv2D(filters, kernel_size, padding=padding, strides=strides)(conv)\n",
        "    return conv\n",
        "\n",
        "def stem(x, filters, kernel_size=(3, 3), padding=\"same\", strides=1):\n",
        "    conv = Conv2D(filters, kernel_size, padding=padding, strides=strides)(x)\n",
        "    conv = conv_block(conv, filters, kernel_size=kernel_size, padding=padding, strides=strides)\n",
        "    \n",
        "    shortcut = Conv2D(filters, kernel_size=(1, 1), padding=padding, strides=strides)(x)\n",
        "    shortcut = bn_act(shortcut, act=False)\n",
        "    \n",
        "    output = Add()([conv, shortcut])\n",
        "    return output\n",
        "\n",
        "def residual_block(x, filters, kernel_size=(3, 3), padding=\"same\", strides=1):\n",
        "    res = conv_block(x, filters, kernel_size=kernel_size, padding=padding, strides=strides)\n",
        "    res = conv_block(res, filters, kernel_size=kernel_size, padding=padding, strides=1)\n",
        "    \n",
        "    shortcut = Conv2D(filters, kernel_size=(1, 1), padding=padding, strides=strides)(x)\n",
        "    shortcut = bn_act(shortcut, act=False)\n",
        "    \n",
        "    output = Add()([shortcut, res])\n",
        "    return output\n",
        "\n",
        "def upsample_concat_block(x, xskip):\n",
        "    u = UpSampling2D((2, 2))(x)\n",
        "    c = Concatenate()([u, xskip])\n",
        "    return c"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t6g5wofl43u1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def ResUNet():\n",
        "    f = [16, 32, 64, 128, 256]\n",
        "    inputs = Input((512, 512, 1))\n",
        "    \n",
        "    ## Encoder\n",
        "    e0 = inputs\n",
        "    e1 = stem(e0, f[0])\n",
        "    e2 = residual_block(e1, f[1], strides=2)\n",
        "    e3 = residual_block(e2, f[2], strides=2)\n",
        "    e4 = residual_block(e3, f[3], strides=2)\n",
        "    e5 = residual_block(e4, f[4], strides=2)\n",
        "    \n",
        "    ## Bridge\n",
        "    b0 = conv_block(e5, f[4], strides=1)\n",
        "    b1 = conv_block(b0, f[4], strides=1)\n",
        "    \n",
        "    ## Decoder\n",
        "    u1 = upsample_concat_block(b1, e4)\n",
        "    d1 = residual_block(u1, f[4])\n",
        "    \n",
        "    u2 = upsample_concat_block(d1, e3)\n",
        "    d2 = residual_block(u2, f[3])\n",
        "    \n",
        "    u3 = upsample_concat_block(d2, e2)\n",
        "    d3 = residual_block(u3, f[2])\n",
        "    \n",
        "    u4 = upsample_concat_block(d3, e1)\n",
        "    d4 = residual_block(u4, f[1])\n",
        "    \n",
        "    outputs = Conv2D(1, (1, 1), padding=\"same\", activation=\"sigmoid\")(d4)\n",
        "    model = Model(inputs, outputs)\n",
        "    plot_model(model, to_file='ResUNet.png')\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_vB_klA6kajn",
        "colab_type": "code",
        "outputId": "7e73be95-51ac-4a17-fefc-3febc59b271b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        }
      },
      "source": [
        "# history = model.fit(X, y, epochs=20, shuffle=True, validation_split=0.1, batch_size=8)\n",
        "history = model.fit_generator(train_gen, shuffle=True, steps_per_epoch=750, epochs=10)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "750/750 [==============================] - 109s 145ms/step - loss: 0.4229 - dice_coef: 0.5771\n",
            "Epoch 2/10\n",
            "750/750 [==============================] - 111s 148ms/step - loss: 0.4033 - dice_coef: 0.5967\n",
            "Epoch 3/10\n",
            "750/750 [==============================] - 111s 148ms/step - loss: 0.3752 - dice_coef: 0.6248\n",
            "Epoch 4/10\n",
            "750/750 [==============================] - 111s 148ms/step - loss: 0.3893 - dice_coef: 0.6107\n",
            "Epoch 5/10\n",
            "750/750 [==============================] - 110s 147ms/step - loss: 0.3686 - dice_coef: 0.6314\n",
            "Epoch 6/10\n",
            "750/750 [==============================] - 111s 148ms/step - loss: 0.3662 - dice_coef: 0.6338\n",
            "Epoch 7/10\n",
            "750/750 [==============================] - 111s 147ms/step - loss: 0.3380 - dice_coef: 0.6620\n",
            "Epoch 8/10\n",
            "750/750 [==============================] - 110s 147ms/step - loss: 0.3581 - dice_coef: 0.6419\n",
            "Epoch 9/10\n",
            "750/750 [==============================] - 111s 148ms/step - loss: 0.3339 - dice_coef: 0.6661\n",
            "Epoch 10/10\n",
            "750/750 [==============================] - 110s 147ms/step - loss: 0.3391 - dice_coef: 0.6609\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dbP7h0Zp9Dq-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('./drive/My Drive/BTS_final.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rk7fTFurN-oh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "img = cv2.imread('segmentation_dataset/tumorImage/tumor/151.png', 0) / 255.\n",
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(img, cmap='gray')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83dHXWsEO90Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "# img = cv2.resize(img, (256, 256))\n",
        "img = img.reshape(-1, 512, 512, 1)\n",
        "y_pred = model.predict(img)\n",
        "\n",
        "y = np.squeeze(y_pred)\n",
        "plt.imshow(y, cmap='gray')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZIe9oseSNJW",
        "colab_type": "code",
        "outputId": "286c0c81-6a21-4601-e71c-9b67a815f5f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wed Jul 24 10:06:40 2019       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 418.67       Driver Version: 410.79       CUDA Version: 10.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   53C    P0    28W /  70W |  14737MiB / 15079MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qvQQcdOvdS5E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nXWNJdoQ3nlo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}